{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1516242,"sourceType":"datasetVersion","datasetId":893591}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-22T12:10:34.563361Z\",\"iopub.execute_input\":\"2025-04-22T12:10:34.563795Z\",\"iopub.status.idle\":\"2025-04-22T12:10:43.374085Z\",\"shell.execute_reply.started\":\"2025-04-22T12:10:34.563762Z\",\"shell.execute_reply\":\"2025-04-22T12:10:43.373198Z\"},\"_kg_hide-input\":false,\"_kg_hide-output\":true}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-22T12:10:43.375143Z\",\"iopub.execute_input\":\"2025-04-22T12:10:43.375521Z\",\"iopub.status.idle\":\"2025-04-22T12:10:56.946819Z\",\"shell.execute_reply.started\":\"2025-04-22T12:10:43.375486Z\",\"shell.execute_reply\":\"2025-04-22T12:10:56.946144Z\"}}\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport random\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-22T12:10:56.947616Z\",\"iopub.execute_input\":\"2025-04-22T12:10:56.948246Z\",\"iopub.status.idle\":\"2025-04-22T12:10:56.952085Z\",\"shell.execute_reply.started\":\"2025-04-22T12:10:56.948211Z\",\"shell.execute_reply\":\"2025-04-22T12:10:56.951481Z\"}}\nIMG_WIDTH = 512\nIMG_HEIGHT = 512\nIMG_CHANNELS = 3\n\nTRAIN_PATH = \"../input/massachusetts-roads-dataset/tiff/train/\"\nTRAIN_MASK_PATH = \"../input/massachusetts-roads-dataset/tiff/train_labels/\"\n\nVAL_PATH = \"../input/massachusetts-roads-dataset/tiff/val/\"\nVAL_MASK_PATH = \"../input/massachusetts-roads-dataset/tiff/val_labels/\"\n\nTEST_PATH = '../input/massachusetts-roads-dataset/tiff/test/'\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-22T12:10:56.954146Z\",\"iopub.execute_input\":\"2025-04-22T12:10:56.954342Z\",\"iopub.status.idle\":\"2025-04-22T12:10:56.986655Z\",\"shell.execute_reply.started\":\"2025-04-22T12:10:56.954324Z\",\"shell.execute_reply\":\"2025-04-22T12:10:56.985731Z\"}}\ntrain_imgs = sorted(os.listdir(TRAIN_PATH))\ntrain_masks = sorted(os.listdir(TRAIN_MASK_PATH))\n\nval_imgs = sorted(os.listdir(VAL_PATH))\nval_masks = sorted(os.listdir(VAL_MASK_PATH))\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-22T12:10:56.988002Z\",\"iopub.execute_input\":\"2025-04-22T12:10:56.988231Z\"}}\nX_train = np.zeros((len(train_imgs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_masks), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n\nprint(\"Processing training data...\")\n\nfor i, file_name in tqdm(enumerate(train_imgs), total=len(train_imgs)):\n    img = imread(os.path.join(TRAIN_PATH, file_name))[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[i] = img\n\n    mask = imread(os.path.join(TRAIN_MASK_PATH, train_masks[i]))\n    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    mask = np.expand_dims(mask, axis=-1)\n    Y_train[i] = mask > 0.5\n\n\n# %% [code]\n#for validation set\nX_val = np.zeros((len(val_imgs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_val = np.zeros((len(val_masks), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n\nprint(\"Processing validation data...\")\n\nfor i, file_name in tqdm(enumerate(val_imgs), total=len(val_imgs)):\n    img = imread(os.path.join(VAL_PATH, file_name))[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_val[i] = img\n\n    mask = imread(os.path.join(VAL_MASK_PATH, val_masks[i]))\n    mask = resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    mask = np.expand_dims(mask, axis=-1)\n    Y_val[i] = mask > 0.5\n\n\n# %% [code]\ntest_imgs = sorted(os.listdir(TEST_PATH))\n\nX_test = np.zeros((len(test_imgs), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n\nprint(\"Processing test data...\")\n\nfor i, file_name in tqdm(enumerate(test_imgs), total=len(test_imgs)):\n    img = imread(os.path.join(TEST_PATH, file_name))[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_test[i] = img\n\n\n# %% [code]\nix = random.randint(0, len(X_train) - 1)\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.imshow(X_train[ix])\nplt.title(\"Input Image\")\nplt.subplot(1,2,2)\nplt.imshow(Y_train[ix].squeeze(), cmap='gray')\nplt.title(\"Mask\")\nplt.show()\n\n\n# %% [code]\n#BUILDING THE U-NET MODEL\n\ninputs = tf.keras.layers.Input((IMG_WIDTH,IMG_HEIGHT,IMG_CHANNELS))\n\n#CONVOLUTION LAYERS\n#c = tf.keras.layers.Conv2D(feature size, kernel size, activation,kernel_initializer(he_normal usese normal distribution for assigning initial weights to nn),padding)(on what we should apply this)\n\n#layers takes in only floating point values so change img_width, ... to float by dividing by 255 as image values go from 0 to 255\n\ns=tf.keras.layers.Lambda(lambda x: x/255)(inputs)\n\nc1 = tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',kernel_initializer ='he_normal',padding = 'same')(s)\nc1 = tf.keras.layers.Dropout(0.1)(c1) #dropout of 10% to prevent overfitting\nc1 = tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',kernel_initializer ='he_normal',padding = 'same')(c1)\n#maxpooling poolsize= 2x2\np1 = tf.keras.layers.MaxPooling2D(2,2)(c1) \n\nc2 = tf.keras.layers.Conv2D(32,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)\nc2 = tf.keras.layers.Conv2D(32,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(c2)\np2 = tf.keras.layers.MaxPooling2D(2,2)(c2)\n\nc3 = tf.keras.layers.Conv2D(64,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(p2)\nc3 = tf.keras.layers.Dropout(0.2)(c3)\nc3 = tf.keras.layers.Conv2D(64,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(c3)\np3 = tf.keras.layers.MaxPooling2D(2,2)(c3)\n\nc4 = tf.keras.layers.Conv2D(128,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(p3)\nc4 = tf.keras.layers.Dropout(0.2)(c4)\nc4 = tf.keras.layers.Conv2D(128,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(c4)\np4 = tf.keras.layers.MaxPooling2D(2,2)(c4)\n\nc5 = tf.keras.layers.Conv2D(256,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(p4)\nc5 = tf.keras.layers.Dropout(0.3)(c5)\nc5 = tf.keras.layers.Conv2D(256,(3,3),activation= 'relu',kernel_initializer = 'he_normal',padding ='same')(c5)\n#no pool for the last layer of  Downsampling\n\n#explanding path /upsampling\n#note conv size for upsampling is 2x2 acc to image\nu6= tf.keras.layers.Conv2DTranspose(128,(2,2),strides= (2,2),padding ='same')(c5)\nu6 = tf.keras.layers.concatenate([u6,c4])\nc6 = tf.keras.layers.Conv2D(128,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(u6)\nc6=tf.keras.layers.Dropout(0.2)(c6)\nc6 = tf.keras.layers.Conv2D(128,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(c6)\n\nu7= tf.keras.layers.Conv2DTranspose(64,(2,2),strides= (2,2),padding ='same')(c6)\nu7 = tf.keras.layers.concatenate([u7,c3])\nc7 = tf.keras.layers.Conv2D(64,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)\nc7 = tf.keras.layers.Conv2D(64,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(c7)\n\nu8 = tf.keras.layers.Conv2DTranspose(32,(2,2),strides= (2,2),padding ='same')(c7)\nu8 = tf.keras.layers.concatenate([u8,c2])\nc8 = tf.keras.layers.Conv2D(32,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(u8)\nc8 = tf.keras.layers.Dropout(0.1)(c8)\nc8 = tf.keras.layers.Conv2D(32,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(c8)\n\nu9 = tf.keras.layers.Conv2DTranspose(16,(2,2),strides= (2,2),padding ='same')(c8)\nu9 = tf.keras.layers.concatenate([u9,c1],axis =3)\nc9 = tf.keras.layers.Conv2D(16,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(u9)\nc9 = tf.keras.layers.Dropout(0.1)(c9)\nc9 = tf.keras.layers.Conv2D(16,(3,3),activation ='relu',kernel_initializer = 'he_normal',padding = 'same')(c9)\n\n#for o/p as per picture, feature size =1 and conv kernel size also is 1x1\noutputs = tf.keras.layers.Conv2D(1,(1,1),activation = 'sigmoid')(c9)\n\n#saving and compiling the model\n\nmodel = tf.keras.Model(inputs=[inputs],outputs =[outputs])\nmodel.compile(optimizer = 'adam',loss ='binary_crossentropy',metrics=['accuracy'])\nmodel.summary()\n\n\n# %% [code]\n#model checkpoint\n\ncheckpointer=tf.keras.callbacks.ModelCheckpoint('unet_best_model.keras',verbose=1,save_best_only = True)\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor ='val_loss', patience=2),\n    tf.keras.callbacks.TensorBoard(log_dir='logs'),\n    checkpointer\n]\n\nresults = model.fit(X_train,Y_train,validation_split=0.1,batch_size=16, epochs=25,callbacks=callbacks)\n\n# %% [code]\npreds_train_t = model.predict(X_train, batch_size=16) \npreds_val_t = model.predict(X_val, batch_size=16)    \n\n# %% [code]\nix = random.randint(0,len(preds_train_t)-1)\n\nplt.imshow(X_train[ix])\nplt.title(\"Train Image\")\nplt.show()\n\nplt.imshow(np.squeeze(Y_train[ix]), cmap='gray')\nplt.title(\"Ground Truth Mask\")\nplt.show()\n\nplt.imshow(np.squeeze(preds_train_t[ix]), cmap='gray')\nplt.title(\"Predicted Mask\")\nplt.show()\n\n# For validation\nix = random.randint(0,len(preds_val_t)-1)\n\nplt.imshow(X_train[int(X_train.shape[0]*0.9):][ix])\nplt.title(\"Validation Image\")\nplt.show()\n\nplt.imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]), cmap='gray')\nplt.title(\"Validation Ground Truth Mask\")\nplt.show()\n\nplt.imshow(np.squeeze(preds_val_t[ix]), cmap='gray')\nplt.title(\"Validation Predicted Mask\")\nplt.show()\n\n\n# %% [code]\ndef overlay_mask_on_image(image, mask, color=(255, 0, 0), alpha=0.7):\n    overlay = image.copy()\n    mask = np.squeeze(mask)\n\n    if len(mask.shape) == 2:  # make sure it's 2D\n        mask = mask.astype(bool)\n\n    overlay[mask] = (1 - alpha) * overlay[mask] + alpha * np.array(color)\n    return overlay.astype(np.uint8)\n\n\n# %% [code]\n# Generate test predictions (AFTER loading model)\npreds_test_t = model.predict(X_test, batch_size=16)\n\n# Threshold predictions to binary mask\npreds_test_t = (preds_test_t > 0.5).astype(np.float32)\n\n\n# %% [code]\nix = random.randint(0, len(X_test) - 1)\noriginal_image = X_test[ix]\npredicted_mask = preds_test_t[ix]\npredicted_mask = tf.image.resize(predicted_mask, (512, 512)).numpy()\n\nhighlighted = overlay_mask_on_image(original_image, predicted_mask, color=(255, 0, 0), alpha=0.5)\n\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nplt.imshow(original_image)\nplt.title(\"Original Image\")\n\nplt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(predicted_mask), cmap='gray')\nplt.title(\"Predicted Mask\")\n\nplt.subplot(1, 3, 3)\nplt.imshow(highlighted)\nplt.title(\"Segmented Roads Overlay\")\n\nplt.show()\n\n\n# %% [code]\n#ROAD TYPE CLASSIFICATION \n\nroad_types = ['Highway', 'Main Road', 'Street', 'Dirt Road']\n\nimport cv2\n\nfrom tensorflow.image import resize\n\ndef extract_road_patch(img, mask):\n    mask = tf.image.resize(mask, (img.shape[0], img.shape[1]))  # Resize to 512x512\n    mask = tf.squeeze(mask).numpy() > 0.5                       # Threshold to boolean mask\n    img = (img * 255).astype(np.uint8)                          # Convert to uint8 if needed\n    patch = img.copy()\n    patch[~mask] = 0\n    return patch\n\n\nroad_patches = []\nfor i in range(len(preds_train_t)):\n    road_patches.append(extract_road_patch(X_train[i], preds_train_t[i]))\nroad_patches = np.array(road_patches)\n\n\n# %% [code]\nfor i in range(5):\n    patch = extract_road_patch(X_train[i], preds_train_t[i])\n    plt.imshow(patch)\n    plt.title(f\"Sample {i}\")\n    plt.show()\n\n\n# %% [code]\nfrom sklearn.ensemble import RandomForestClassifier\nfrom skimage.measure import regionprops, label\nfrom sklearn.preprocessing import StandardScaler\nimport cv2\n\n# Sample training data for classifier (you must build real data here)\nX_cls_train = []\ny_cls_train = []\n\n# Dummy classifier setup\nclf = RandomForestClassifier()\n\ndef extract_features(mask):\n    mask = mask.squeeze().astype(np.uint8)\n    labeled_mask = label(mask)\n    props = regionprops(labeled_mask)\n    \n    if not props:\n        return [0, 0, 0, 0]\n    \n    largest_region = max(props, key=lambda x: x.area)\n    \n    area = largest_region.area\n    eccentricity = largest_region.eccentricity\n    solidity = largest_region.solidity\n    extent = largest_region.extent\n    \n    return [area, eccentricity, solidity, extent]\n\n# Dummy training loop\nfor i in range(len(Y_train)):\n    features = extract_features(Y_train[i])\n    label_type = np.random.choice(road_types)  # Replace with real labels if available\n    X_cls_train.append(features)\n    y_cls_train.append(road_types.index(label_type))\n\n# Train the classifier\nscaler = StandardScaler()\nX_cls_train_scaled = scaler.fit_transform(X_cls_train)\nclf.fit(X_cls_train_scaled, y_cls_train)\n\n# Predict road type from new test mask\nix = random.randint(0, len(preds_test_t)-1)\ntest_mask = preds_test_t[ix]\nfeatures_test = extract_features(test_mask)\nfeatures_test_scaled = scaler.transform([features_test])\npredicted_road_type = road_types[clf.predict(features_test_scaled)[0]]\n\nprint(\"Predicted Road Type:\", predicted_road_type)\n\n\n# %% [code]\nplt.figure(figsize=(10,5))\nplt.imshow(X_test[ix])\nplt.title(f\"Predicted Road Type: {predicted_road_type}\")\nplt.show()\n\n\n# %% [code]\nfrom IPython.display import FileLink\nFileLink('unet_best_model.keras')  # Creates downloadable link\n\n\n# %% [code]\n# In Kaggle notebook only\nimport pickle\nimport tempfile\n\n# Enable Keras pickling\ndef make_keras_picklable():\n    def __getstate__(self):\n        with tempfile.NamedTemporaryFile(suffix='.keras') as tmp:\n            self.save(tmp.name)\n            return {'model_str': tmp.read()}\n    \n    def __setstate__(self, state):\n        with tempfile.NamedTemporaryFile(suffix='.keras') as tmp:\n            tmp.write(state['model_str'])\n            model = tf.keras.models.load_model(tmp.name)\n            self.__dict__.update(model.__dict__)\n            \n    tf.keras.Model.__getstate__ = __getstate__\n    tf.keras.Model.__setstate__ = __setstate__\n\nmake_keras_picklable()\n\n# Save as PKL\nwith open('unet_roads.pkl', 'wb') as f:\n    pickle.dump(model, f)\n\n\n# %% [code]\nwith open('unet_roads.pkl','rb') as f:\n    pkl_model = pickle.load(f)\nassert np.allclose(model.predict(X_test), pkl_model.predict(X_test))\n","metadata":{"_uuid":"75c2c2a7-523d-4752-a8c0-921bfc6752d9","_cell_guid":"886dbb99-c5a7-43e3-a691-46195bb30f3e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}